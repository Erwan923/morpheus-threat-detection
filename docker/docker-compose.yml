version: '3.8'

services:
  triton:
    image: nvcr.io/nvidia/tritonserver:24.09-py3
    container_name: morpheus-triton
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    volumes:
      - ./models:/models
    command: tritonserver --model-repository=/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 5

  morpheus:
    build:
      context: ..
      dockerfile: docker/Dockerfile.gpu
    container_name: morpheus-pipeline
    depends_on:
      triton:
        condition: service_healthy
    volumes:
      - ../examples:/workspace/examples
      - ../results:/workspace/results
      - ../src:/workspace/src
    environment:
      - TRITON_URL=triton:8001
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      python3 src/pipelines/threat_detection.py
      --input examples/data/pcap_dump.jsonlines
      --output results/threats.json
    restart: "no"

  prometheus:
    image: prom/prometheus:latest
    container_name: morpheus-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    restart: unless-stopped

networks:
  default:
    name: morpheus-network
